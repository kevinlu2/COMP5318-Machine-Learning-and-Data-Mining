{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 - Machine Learning and Data Mining \n",
    "\n",
    "## Tutorial 5 - Classification I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semester 2, 2020**\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* To learn about k-NN classification algorithm. \n",
    "* To learn about bag of words features and na誰ve Bayes classifier.\n",
    "* To evaluate classification performance measures.\n",
    "\n",
    "**Instructions:**\n",
    "* Exercises to be completed on IPython notebook such as: \n",
    "   * Ipython 3 (Jupyter) notebook installed on your computer http://jupyter.org/install (you need to have Python installed first https://docs.python.org/3/using/index.html )\n",
    "   * Web-based Ipython notebooks such as Google Colaboratory https://colab.research.google.com/ \n",
    "   \n",
    "* If you are using Jupyter intalled on your computer, Go to File->Open. Drag and drop \"lab5.ipynb\" file to the home interface and click upload. \n",
    "* If you are using Google Colaboratory, Click File->Upload notebook, and and upload \"lab5.ipynb\" file\n",
    "* Complete exercises in \"lab5.ipynb\".\n",
    "* To run the cell you can press Ctrl-Enter or hit the Play button at the top.\n",
    "* Complete all exercises marked with **TODO**.\n",
    "* Save your file when you are done with the exercises, so you can show your tutor next week.\n",
    "\n",
    "Lecturers: Nguyen Hoang Tran \n",
    "\n",
    "Tutors: Canh Dinh, Chen Chen, Claire Hardgrove, Fengxiang He, Henry Weld, Yixuan Zhang, Zhiyi Wang, Thomas Selvaraj."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. k-nearest neighbors (k-NN) classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1:* **Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(([2,1,3,5,3,10,9,5,8,11,15,13,16],[1,0,3,5,2,12,11,10,7,9,11,15,16])).T\n",
    "y = np.asarray([0,0,0,0,0,1,1,1,1,1,2,2,2])[:,np.newaxis]\n",
    "\n",
    "print('X=\\n',X)\n",
    "print('y=\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y)\n",
    "\n",
    "X_q = np.asarray(([4.5],[5])).T #query point\n",
    "\n",
    "pos_of_class0 = np.where(y==0)[0] #class 0 points\n",
    "pos_of_class1 = np.where(y==1)[0] #class 1 points\n",
    "pos_of_class2 = np.where(y==2)[0] #class 2 points\n",
    "\n",
    "pl.scatter(X[pos_of_class0,0], X[pos_of_class0,1], c='r', edgecolor='') #class = 0\n",
    "pl.scatter(X[pos_of_class1,0], X[pos_of_class1,1], c='g', edgecolor='') #class = 1\n",
    "pl.scatter(X[pos_of_class2,0], X[pos_of_class2,1], c='b', edgecolor='') #class = 2\n",
    "pl.scatter(X_q[:,0], X_q[:,1], marker='*', s=100, c='k', edgecolor='') #class to be determined\n",
    "for i in range(N): \n",
    "    pl.scatter(X[i,0]+0.4, X[i,1]-0.5, s=100, marker=\"$ {} $\".format(i)) #positions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2:* **Determining the nearest neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = ((X - X_q)**2).sum(axis=1) #calculate distance between X_q and each training point\n",
    "arg_ascending = np.argsort(dis) #arrange distances in the ascending order\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print('Distance between X_q and each training point= \\n', dis)\n",
    "print('Index of nearest neighbors in training data=\\n', arg_ascending) #Check the plot in Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3:* **Determining the classes of k-nearest neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5 #Let us consider 5-nearest neighbors \n",
    "\n",
    "classes = np.zeros(3)\n",
    "for i in range(K):\n",
    "    if y[arg_ascending[i]]==0: #class = 0\n",
    "        print(i, 'th nearest neighbor belongs to class 0.')\n",
    "        classes[0] += 1\n",
    "    elif y[arg_ascending[i]]==1: #class = 1\n",
    "        print(i, 'th nearest neighbor belongs to class 1.')\n",
    "        classes[1] += 1\n",
    "    elif y[arg_ascending[i]]==2: #class = 2\n",
    "        print(i, 'th nearest neighbor belongs to class 2.')\n",
    "        classes[2] += 1\n",
    "    else:\n",
    "        print('Error - Invalid class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4:* **Determining the class of X_q**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = classes/K\n",
    "\n",
    "print('classes', classes)\n",
    "print('probabilities=', prob)\n",
    "print('ANSWER: X_q blongs to', np.argmax(prob), 'th class!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_knn(X, y, K, X_q):\n",
    "    dis = ((X - X_q)**2).sum(axis=1) #calculate distance between X_q and each training point\n",
    "    arg_ascending = np.argsort(dis)\n",
    "    \n",
    "    classes = np.zeros(3)\n",
    "    for i in range(K):\n",
    "        if y[arg_ascending[i]]==0: #class = 0\n",
    "            classes[0] += 1\n",
    "        elif y[arg_ascending[i]]==1: #class = 1\n",
    "            classes[1] += 1\n",
    "        elif y[arg_ascending[i]]==2: #class = 2\n",
    "            classes[2] += 1\n",
    "        else:\n",
    "            print('Error - Invalid class')\n",
    "            \n",
    "    return np.argmax(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        X_q = np.asarray(([i],[j])).T #query point\n",
    "        class_out = calc_knn(X, y, 4, X_q)\n",
    "        \n",
    "        if class_out ==0:\n",
    "            pl.scatter(X_q[:,0], X_q[:,1], s=50, c='r', edgecolor='')\n",
    "        elif class_out ==1:\n",
    "            pl.scatter(X_q[:,0], X_q[:,1], s=50, c='g', edgecolor='')\n",
    "        else:\n",
    "            pl.scatter(X_q[:,0], X_q[:,1], s=50, c='b', edgecolor='')\n",
    "            \n",
    "pl.title('Decision surface')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.1 (optional):** Plot *p(class=0|Data, K)*, *p(class=1|Data, K)* and *p(class=2|Data, K)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "g = pd.read_csv('training.csv',delimiter=',').values\n",
    "X = np.float_(g[:,0:2])\n",
    "y = np.float_(g[:,2:3])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y)\n",
    "\n",
    "pos_of_class0 = np.where(y==0)[0] #positions of class 0\n",
    "pos_of_class1 = np.where(y==1)[0] #positions of class 1\n",
    "pos_of_class2 = np.where(y==2)[0] #positions of class 2\n",
    "\n",
    "pl.scatter(X[pos_of_class0,0], X[pos_of_class0,1], c='r', edgecolor='') #class = 0\n",
    "pl.scatter(X[pos_of_class1,0], X[pos_of_class1,1], c='g', edgecolor='') #class = 1\n",
    "pl.scatter(X[pos_of_class2,0], X[pos_of_class2,1], c='b', edgecolor='') #class = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2.** Determine the class of X_q data in test.csv. Hence develop the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "g_test = pd.read_csv('test.csv',delimiter=',').values\n",
    "X_test = np.float_(g_test[:,0:2])\n",
    "y_test = np.float_(g_test[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class = np.empty((len(y_test),1))\n",
    "for i in range(len(y_test)):\n",
    "    out_class[i,0] = calc_knn(X, y, 4, X_test[i,:])\n",
    "\n",
    "print(np.hstack((out_class,y_test)))\n",
    "\n",
    "#Method 1\n",
    "confusion = np.zeros((3,3))\n",
    "for i in range(len(out_class)):\n",
    "   if out_class[i] == 0 and y_test[i] == 0:\n",
    "       confusion[0,0] += 1\n",
    "   elif out_class[i] == 0 and y_test[i] == 1:\n",
    "       confusion[1,0] += 1\n",
    "   elif out_class[i] == 0 and y_test[i] == 2:\n",
    "       confusion[0,2] += 1\n",
    "   elif out_class[i] == 1 and y_test[i] == 0:\n",
    "       confusion[0,1] += 1\n",
    "   elif out_class[i] == 1 and y_test[i] == 1:\n",
    "       confusion[1,1] += 1\n",
    "   elif out_class[i] ==1 and y_test[i] == 2:\n",
    "       confusion[2,1] += 1\n",
    "   elif out_class[i] == 2 and y_test[i] == 0:\n",
    "       confusion [2,0] += 1\n",
    "   elif out_class[i] ==2 and y_test[i] == 1:\n",
    "       confusion[1,2] += 1\n",
    "   else:\n",
    "       confusion[2,2] += 1\n",
    "print(confusion)\n",
    "\n",
    "#Method 2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, out_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na誰ve Bayes Classifier (NBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian inference is based on,\n",
    "\n",
    "\\begin{equation}\n",
    "    posterior = \\frac{likelihood \\times prior}{evidence}\n",
    "\\end{equation}\n",
    "\n",
    "The main assumption in na誰ve Bayes is ***conditional independence***.\n",
    "\n",
    "The na誰ve Bayes classifier (NBC) is given by,\n",
    "\\begin{equation}\n",
    "    \\hat{y} = \\text{argmax}_{k \\in {1,2,...K}} \\Big( p(C_k) \\prod_{j=1}^D p(x_j|C_k) \\Big) \\in \\{C_k\\}_{k=1}^K\n",
    "\\end{equation}\n",
    "\n",
    "where $C_k$ is the $k^{th}$ class when there are $K$ classes. If $K=2$, i.e. $k \\in \\{1,2\\}$, then the classifier is called a binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us consider a simple spam filtering algorithm based on the Nave bayes binary classifier..\n",
    "\n",
    "The following algorithm is only for demonstration. It can be developed more efficiently. Read Section 3.5 of Machine Learning Kevin by P. Murphy for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1:* **Define training data and vocabulary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "spam = [['million dollar offer'],\n",
    "        ['secret offer today'],\n",
    "        ['send your password online to win one million'],\n",
    "        ['send ten dollar to win million dollar'],\n",
    "        ['confirm your secret password to win monthly gifts']]\n",
    "\n",
    "ham =[['christmas offer for our valued qantas customer'],\n",
    "      ['confirm your monthly bill online or by calling to customer services'],\n",
    "      ['win by booking it using qantas points'],\n",
    "      ['dear customer : confirm your booking']]\n",
    "\n",
    "voc = ['million', 'dollar', 'offer', 'send', 'password', 'win', 'customer', 'booking', 'bill', \n",
    "       'online', 'monthly', 'qantas', 'confirm']\n",
    "\n",
    "#Note: some sentences are deformed for simplicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2*: **Calculate class probabilities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class_prob(cat, voc): #cat=ham or spam  and voc=voc\n",
    "    class_prob = np.zeros((len(voc),1)) #define a 'zeros' array to store class probabilities\n",
    "    for ith_class_email in cat: #for each email in cat\n",
    "        words_in_ith_class_email = ith_class_email[0].split() #split the ith email into words\n",
    "        words_in_ith_class_email = list(set(words_in_ith_class_email)) #remove duplicated words\n",
    "        for word in words_in_ith_class_email: #for each word in the splitted email\n",
    "            i = 0\n",
    "            for voc_word in voc: #for each element in voc\n",
    "                if voc_word in word:\n",
    "                    class_prob[i] += 1 # incrmenet the ith element of class_prob, if voc element is in word\n",
    "                i += 1\n",
    "    return class_prob/len(cat) #divide the count by length of cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_class_prob = calc_class_prob(ham, voc)\n",
    "spam_class_prob = calc_class_prob(spam, voc)\n",
    "\n",
    "print(ham_class_prob)\n",
    "print(spam_class_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3:* **Determine if words in a new email are in the vocabulary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ['win online offer'] #new email\n",
    "\n",
    "prob_vector = np.zeros((len(voc)), dtype=bool) #define a 'True' array to store class probabilities\n",
    "words_in_new = new[0].split() #split the new email into words\n",
    "words_in_new = list(set(words_in_new)) #remove duplicated words\n",
    "i = 0\n",
    "for voc_word in voc: #for each element in voc\n",
    "    if voc_word in words_in_new: \n",
    "        prob_vector[i] = True #set the ith element of prob_vector to True, if voc element is in word\n",
    "    else:\n",
    "        prob_vector[i] = False #set the ith element of prob_vector to False, otherwise\n",
    "    i += 1\n",
    "print(prob_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4:* **Considering independence, calculate the probabilities that word in the new email appear in i) ham messages ii) spam messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ham = 1\n",
    "for i in range(len(prob_vector)):\n",
    "    if prob_vector[i] == True:\n",
    "        prob_ham *= ham_class_prob[i]\n",
    "    else:\n",
    "        prob_ham *= (1 - ham_class_prob[i])\n",
    "#alternative: np.prod(ham_class_prob[np.where(prob_vector==True)]) * np.prod(1-ham_class_prob[np.where(prob_vector==False)])\n",
    "        \n",
    "prob_spam = 1\n",
    "for i in range(len(prob_vector)):\n",
    "    if prob_vector[i] == True:\n",
    "        prob_spam *= spam_class_prob[i]\n",
    "    else:\n",
    "        prob_spam *= (1 - spam_class_prob[i])\n",
    "\n",
    "print(prob_ham, prob_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5:* If 30% of emails are typically spams, calculate the probability that the *new* email is a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 0.3\n",
    "p_ham = 1 - p_spam\n",
    "\n",
    "p_spam_given_new = (prob_spam*p_spam)/(prob_spam*p_spam + prob_ham*p_ham) #Bayes theorem\n",
    "print('p(spam|new_email)=', p_spam_given_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    Precision (p) = \\frac{TP}{TP+FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    Recall (r) = \\frac{TP}{TP+FN}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    F\\_measure (F) = \\frac{2rp}{r+p} = \\frac{2TP}{2TP+FN+FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    TPR = \\frac{TP}{TP+FN} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    FPR = \\frac{FP}{FP+TN} \n",
    "\\end{equation}\n",
    "\n",
    "Receiver Operating Characteristic (ROC) is a plot of TPR vs FPR. \n",
    "\n",
    "Note that area=0.5 for random guess and area=1 for an idean classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1:** Develop the confusion matrix and calculate precision, recall and F-measure based on the following test set. Calculate the area under Receiver Operating Characteristic (ROC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer: \n",
    "       https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf\n",
    "       http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = [['secret million dollar'],\n",
    "        ['secret offer today']]\n",
    "\n",
    "ham =[['confirm christmas'],\n",
    "      ['qantas monthly booking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g.NOTE: THIS IS JUST A GENERIC EXAMPLE USING SKLEARN. YOU NEED TO CALCULATE predicted_prob using the above algorithm.\n",
    "from sklearn import metrics\n",
    "actual_y = np.array([0, 0, 0, 1, 1, 1])\n",
    "predicted_prob = np.array([0.1, 0.1, 0.2, 0.6, 0.5, 0.2])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual_y, predicted_prob, pos_label=1)\n",
    "print(' fpr={},\\n tpr={},\\n thresholds={}'.format(fpr, tpr, thresholds))\n",
    "\n",
    "#fpr = Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "#tpr = Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i]\n",
    "#thresholds = set(predicted_prob)\n",
    "#Decreasing thresholds on the decision function used to compute fpr and tpr.thresholds[0] \n",
    "#represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "\n",
    "pl.scatter(fpr, tpr)\n",
    "pl.plot(fpr, tpr)\n",
    "pl.xlabel('fpr'); pl.ylabel('tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: THIS IS JUST A GENERIC EXAMPLE\n",
    "#This is how it works\n",
    "pos_class_label = 1 #specify which class is positive \n",
    "thresholds = np.sort(np.unique(predicted_prob)) #let the thresholds be \n",
    "fpr_array = np.empty(thresholds.shape)\n",
    "tpr_array = np.empty(thresholds.shape)\n",
    "\n",
    "def construct_conf_mat(actual_y, predicted_prob, pos_class_label, thresh=0.5):\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    for i in range(actual_y.shape[0]):\n",
    "        if predicted_prob[i] >= thresh:\n",
    "            if actual_y[i] == pos_class_label:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if actual_y[i] == pos_class_label:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    return fp, tp, fn, tn\n",
    "\n",
    "for thresh_i, thresh in enumerate(thresholds):\n",
    "    #construct the confusion matrix for each threshold\n",
    "    fp, tp, fn, tn = construct_conf_mat(actual_y, predicted_prob, pos_class_label, thresh)\n",
    "\n",
    "    fpr_array[thresh_i] = fp/(fp + tn)\n",
    "    tpr_array[thresh_i] =  tp/(tp + fn)\n",
    "\n",
    "print(fpr_array, tpr_array)\n",
    "pl.scatter(fpr_array, tpr_array)\n",
    "pl.plot(fpr_array, tpr_array)\n",
    "pl.xlabel('fpr'); pl.ylabel('tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2 (optional):**  Extend the NBC to Bernoulli/Gaussian naive Bayes classifier by considering the full Bayesian treatment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
