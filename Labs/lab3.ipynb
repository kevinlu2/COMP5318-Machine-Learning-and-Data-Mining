{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 - Machine Learning and Data Mining \n",
    "\n",
    "## Tutorial 3 - Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semester 2, 2020**\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* To understand continuous and discrete random variables.\n",
    "* To become familiar with random samples.\n",
    "* To become familiar with metrics in Information Theory.\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "* Exercises to be completed on IPython notebook such as: \n",
    "   * Ipython 3 (Jupyter) notebook installed on your computer http://jupyter.org/install (you need to have Python installed first https://docs.python.org/3/using/index.html )\n",
    "   * Web-based Ipython notebooks such as Google Colaboratory https://colab.research.google.com/ \n",
    "   \n",
    "* If you are using Jupyter intalled on your computer, Go to File->Open. Drag and drop \"lab3.ipynb\" file to the home interface and click upload. \n",
    "* If you are using Google Colaboratory, Click File->Upload notebook, and and upload \"lab3.ipynb\" file\n",
    "* Complete exercises in \"lab3.ipynb\".\n",
    "* To run the cell you can press Ctrl-Enter or hit the Play button at the top.\n",
    "* Complete all exercises marked with **TODO**.\n",
    "* Save your file when you are done with the exercises, so you can show your tutor next week.\n",
    "\n",
    "Lecturers: Nguyen Hoang Tran \n",
    "\n",
    "Tutors: Canh Dinh, Chen Chen, Claire Hardgrove, Fengxiang He, Henry Weld, Yixuan Zhang, Zhiyi Wang, Thomas Selvaraj."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Continuous random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the methods in scipy.stats library for random variables include,\n",
    "* rvs: Random Variates\n",
    "* pdf/pmf: Probability Density/Mass Function\n",
    "* cdf: Cumulative Distribution Function\n",
    "* stats: Return mean, variance, (Fisher’s) skew, or (Fisher’s) kurtosis\n",
    "* moment: non-central moments of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd = 0, 1\n",
    "x = np.linspace(mean - 6*sd, mean + 6*sd, 100)\n",
    "f = st.norm.pdf(x=x, loc=mean, scale=sd)\n",
    "F = st.norm.cdf(x=x, loc=mean, scale=sd)\n",
    "\n",
    "pl.figure(figsize=(10,5))\n",
    "pl.subplot(121)\n",
    "pl.stem(x, f); pl.xlabel('x'); pl.ylabel('f(x)'); pl.title('pdf with mean={} and s.d.={}'.format(mean, sd))\n",
    "pl.subplot(122)\n",
    "pl.stem(x, F); pl.xlabel('x'); pl.ylabel('F(x)'); pl.title('cdf with mean={} and s.d.={}'.format(mean, sd))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.1.1** Change location and scale parameters (e.g. loc=1, scale=0.25) and observe results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Discrete random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2.1** In an urn which contains M=100 different currency bills, n=25 bills are Australian dollars. Plot the pmf and cdf if N=15 bills are randomly drawn *without replacement*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "M, n, N = 100, 25, 15 #Population, Successes, No of draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pseudo-random number generators (PRNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1.1** Discuss how random numbers are generated in a computer (Turing machine). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Sampling from a distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "samples = np.random.normal(mu, sigma, 1000) # or use scipy.stats.rvs(size=1000)\n",
    "\n",
    "count, bins, ignored = pl.hist(samples, bins=30, density=True)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivaraiate normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0, 0)\n",
    "cov = [[1, 1], [1, 10]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, 100000).T\n",
    "\n",
    "#pl.scatter(x, y)\n",
    "pl.hist2d(x, y, 25, density=True) #hexbin\n",
    "pl.xlabel('x'); pl.ylabel('y')\n",
    "pl.colorbar()\n",
    "pl.axis('equal')\n",
    "pl.show()\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2.1** Observe the probability distribution by varying mean and covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is a measure of uncertainty.\n",
    "\\begin{equation}\n",
    "    \\mathrm{H}[x] := \\sum_x p(x)log_n \\frac{1}{p(x)} = -\\sum_x p(x)log_n \\big( p(x) \\big)\n",
    "\\end{equation}\n",
    "\n",
    "If n=2, the unit of measurement is in bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observe how Entropy changes with the spread of data \n",
    "X = np.arange(5)\n",
    "Z = Y = X \n",
    "\n",
    "pX = np.array([ 0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "pY = np.array([ 0.2, 0.2, 0.2, 0.15, 0.25])\n",
    "pZ = np.array([ 0.15, 0.35, 0.25, 0.1, 0.15])\n",
    "\n",
    "pl.figure(figsize=(10,5))\n",
    "pl.subplot(131)\n",
    "pl.stem(X, pX) \n",
    "pl.ylabel('p(X)')\n",
    "\n",
    "pl.subplot(132)\n",
    "pl.stem(Y, pY)\n",
    "pl.ylabel('p(Y)')\n",
    "\n",
    "pl.subplot(133)\n",
    "pl.stem(Z, pZ)\n",
    "pl.ylabel('p(Z)')\n",
    "\n",
    "pl.show()\n",
    "\n",
    "def calc_entropy(p):\n",
    "    return #TODO\n",
    "\n",
    "print(calc_entropy(pX), calc_entropy(pY), calc_entropy(pZ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1.1** Consider the Bernoulli trial of tossing a coin (unfair coin) with event space X. Let $p(X=1)$ be the probability of obtaining a head. Calculate the entopy for $p(X=1) \\in [0,1]$ and show that entopy decreases as the uncertainty decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Kullback-Leibler (KL) divergence or Relative Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL divergence measures how dissimilar two probability distributions are.\n",
    "\\begin{equation}\n",
    "    \\mathrm{KL}(p||q) := \\sum_x p(x) log_n \\frac{p(x)}{q(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KL(p, q):\n",
    "    return #TODO\n",
    "\n",
    "print('KL(p||p)', calc_KL(pX, pX)) #Note min(KL) is zero when iff p=q\n",
    "print('KL(p||q)', calc_KL(pX, pY))\n",
    "print('KL(q||p)', calc_KL(pY, pX)) # Note KL is not symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    p(Y=y|X=x) = \\frac{p(X=x|Y=y) p(Y=y)}{\\sum_{y'} p(X=x|Y=y')p(Y=y')}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.1.1** \n",
    "\n",
    "0.4% of a population is having a particular genetic disorder. In order to test the disorder, a person has undergone a medical test which has a **sensitivity** of 80% (if a person has the disorder, the test result will be positive with a probability of 0.8) and a **false alarm** of 10%. If the test is positive, what is the probability of person the having the particular genetic disorder?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
