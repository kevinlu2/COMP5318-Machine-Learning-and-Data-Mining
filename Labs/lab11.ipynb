{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6X9Qt81eSKNF"
   },
   "source": [
    "## COMP5318 - Machine Learning and Data Mining \n",
    "\n",
    "## Tutorial 11 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uf0tvgOSSKNI"
   },
   "source": [
    "**Semester 2, 2020**\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* To learn about Keras\n",
    "* To learn about Auto-encoders and Convolutional Neural Networks\n",
    "* To use deep learning tricks such as max pooling and dropout\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "* Exercises to be completed on IPython notebook such as: \n",
    "   * Ipython 3 (Jupyter) notebook installed on your computer http://jupyter.org/install (you need to have Python installed first https://docs.python.org/3/using/index.html )\n",
    "   * Web-based Ipython notebooks such as Google Colaboratory https://colab.research.google.com/ \n",
    "   \n",
    "* If you are using Jupyter intalled on your computer, Go to File->Open. Drag and drop \"lab11.ipynb\" file to the home interface and click upload. \n",
    "* If you are using Google Colaboratory, Click File->Upload notebook, and and upload \"lab11.ipynb\" file\n",
    "* Complete exercises in \"lab11.ipynb\".\n",
    "* To run the cell you can press Ctrl-Enter or hit the Play button at the top.\n",
    "* Complete all exercises marked with **TODO**.\n",
    "* Save your file when you are done with the exercises, so you can show your tutor next week.\n",
    "\n",
    "Lecturers: Nguyen Hoang Tran \n",
    "\n",
    "Tutors: Canh Dinh, Chen Chen, Claire Hardgrove, Fengxiang He, Henry Weld, Yixuan Zhang, Zhiyi Wang, Thomas Selvaraj."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdeqNY5VSKNM"
   },
   "source": [
    "## Basic Linear Regression with Keras\n",
    "Keras is a neural networks API running on top of TensorFlow or Theano, seamlessly running on CPUs and GPUs.\n",
    "\n",
    "Check out https://keras.io/.\n",
    "\n",
    "To get familiar with Keras, we first perfor basic linear regression, which is a specific case of a single layer neural netork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VuWMuwyqSKNQ",
    "outputId": "a6f20d16-6ace-4077-a34d-8b4cfafb0f5c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shOaPyyVSKNd"
   },
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "trX = np.linspace(-1, 1, 101)\n",
    "# create a y value which is approximately linear but with some random noise\n",
    "trY = 2 * trX + np.random.randn(*trX.shape) * 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "ezNZrmbrSKNk",
    "outputId": "39fe1ce1-5397-4c5d-c22e-f9143668c3ab"
   },
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "model = Sequential()\n",
    "# TODO: add a layer using linear activation, dimention of input and out put are 1\n",
    "model.add(Dense(input_dim = , units = , kernel_initializer='uniform', activation= ))\n",
    "\n",
    "# TODO: compile model using sgd and meansquare error \n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SvXhLx4GSKNu",
    "outputId": "8d029ca3-0472-486b-db2b-dd5c4ed0ab6b"
   },
   "outputs": [],
   "source": [
    "# Print initial weights\n",
    "weights = model.layers[0].get_weights()\n",
    "w_init = weights[0][0][0]\n",
    "b_init = weights[1][0]\n",
    "print('Linear regression model is initialized with weight w: %.2f, b: %.2f' % (w_init, b_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "A3325U6oSKN0",
    "outputId": "c86b3827-5a4b-4b88-feab-a4d26d0255ac"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "model.fit(trX, trY, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AcCv29nHSKN9",
    "outputId": "ec39c342-0ee7-4926-86b0-6ac8b2c3c217"
   },
   "outputs": [],
   "source": [
    "# Print trained weights\n",
    "weights = model.layers[0].get_weights()\n",
    "w = weights[0][0][0]\n",
    "b = weights[1][0]\n",
    "print('Linear regression model is trained with weight w: %.2f, b: %.2f' % (w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "y1SGZSlfSKOF",
    "outputId": "dcb68e47-a3bb-4270-aba9-9009e9bf50ee"
   },
   "outputs": [],
   "source": [
    "plt.plot(trX, trY, label='data')\n",
    "plt.plot(trX, w_init*trX + b_init, label='init')\n",
    "plt.plot(trX, w*trX + b, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "drlgkrocSKOL",
    "outputId": "83924e8f-2c68-4279-f04f-625726efe519"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMP9QJvjSKOS"
   },
   "source": [
    "## Loading MNIST data from Keras\n",
    "We use one of the dataset included in Keras: MNIST (https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "15BnxlizSKOV",
    "outputId": "fee510af-8b78-4f74-9d4f-1f6149cef82c"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_val = x_test[:5000,:]\n",
    "x_test = x_test[5000:,:]\n",
    "y_val = y_test[:5000]\n",
    "y_test = y_test[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vwe2yjkESKOd"
   },
   "source": [
    "## Simple autoencoder\n",
    "The goal here is to a representation of our data with lower dimension. To do so, autoencoders first transform the data to a low-dimension representation using an encoder network, and then transform the low-dimension representation back to the original space using a decoder network.\n",
    "\n",
    "Here we start with a single fully-connected neural layer as encoder and as decoder. We will be encoding MNIST digit images (dim=784) into a space of dimension 32, hence the compression factor is 784/32 = 24.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALniJzJNSKOg"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Reshape data to fit the autoencoder layout and normalize it\n",
    "x_train_ae = x_train.astype('float32') / 255.\n",
    "x_test_ae = x_test.astype('float32') / 255.\n",
    "x_val_ae = x_val.astype('float32') / 255.\n",
    "x_train_ae = x_train_ae.reshape((len(x_train_ae), np.prod(x_train_ae.shape[1:])))\n",
    "x_test_ae = x_test_ae.reshape((len(x_test_ae), np.prod(x_test_ae.shape[1:])))\n",
    "x_val_ae = x_val_ae.reshape((len(x_val_ae), np.prod(x_val_ae.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pgd9O4_VSKOo"
   },
   "source": [
    "Train the autoencoder to reconstruct MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "yQqnAiJdSKOq",
    "outputId": "ffc734d3-b3a2-4d55-9855-d1a211a8f597"
   },
   "outputs": [],
   "source": [
    "# Configure the model to use a per-pixel binary crossentropy loss, and Adadelta optimizer\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "autoencoder.fit(x_train_ae, x_train_ae, epochs=10, batch_size=256,\n",
    "                shuffle=True, validation_data=(x_val_ae, x_val_ae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DOS_Vy6SKOv"
   },
   "source": [
    "Vizualize the reconstructed inputs and the encoded representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "naB3EncqSKOx",
    "outputId": "2d56fb2c-1c8c-430d-deb3-ff53cfbed9a2"
   },
   "outputs": [],
   "source": [
    "# Retrieve the encoder and decoder as separate networks\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test_ae)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# use Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_ae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUz-K4tCSKO2"
   },
   "source": [
    "Note that the autoencoder is not fully converged yet as it was trained on only 10 epochs. You may want to try and run it for longer to get better digit reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAzh5Zo7SKO4"
   },
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdnQBJmhSKO6"
   },
   "source": [
    "Prepare data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PRgEGNXSKO8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "num_train = 6000 # Max is 60000\n",
    "num_test = 1000 # Max is 5000\n",
    "num_val = 1000 # Max is 5000\n",
    "# Only keep a subset of the data\n",
    "x_train_cnn = x_train[:num_train,:,:,None]\n",
    "y_train_cnn = y_train[:num_train]\n",
    "x_test_cnn = x_test[:num_test,:,:,None]\n",
    "y_test_cnn = y_test[:num_test]\n",
    "x_val_cnn = x_test[:num_val,:,:,None]\n",
    "y_val_cnn = y_test[:num_val]\n",
    "\n",
    "x_train_cnn = x_train_cnn.astype('float32')\n",
    "x_test_cnn = x_test_cnn.astype('float32')\n",
    "x_val_cnn = x_test_cnn.astype('float32')\n",
    "x_train_cnn /= 255.\n",
    "x_test_cnn /= 255.\n",
    "x_val_cnn /= 255.\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train_cnn = keras.utils.to_categorical(y_train_cnn, num_classes)\n",
    "y_test_cnn = keras.utils.to_categorical(y_test_cnn, num_classes)\n",
    "y_val_cnn = keras.utils.to_categorical(y_val_cnn, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "7h-Vvo_wSKPD",
    "outputId": "b99c9f8f-a1a8-42ff-c03e-0efdedcdb5c9"
   },
   "outputs": [],
   "source": [
    "# Create CNN topology\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train_cnn.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "# TODO: add the last layer as softmax actication \n",
    "model.add()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Fit model to data\n",
    "print(epochs)\n",
    "model.fit(x_train_cnn, y_train_cnn, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=(x_val_cnn, y_val_cnn), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "SQGpOVYRSKPL",
    "outputId": "1330011b-0d07-4ea2-986d-b395b0202424"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_cnn, y_test_cnn, batch_size=32, verbose=1)\n",
    "print(\"\\nTest accuracy is {}%\".format(100.0*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnzuveHdSKPQ"
   },
   "source": [
    "### Adding dropout and pooling to the CNN\n",
    "Max pooling and dropouts are tricks that improve deep neural networks.\n",
    "\n",
    "Max pooling (http://yann.lecun.com/exdb/publis/pdf/boureau-icml-10.pdf) speeds up CNN training and encourages CNN to learn translation-invariant features.\n",
    "Dropout (https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) is a regularisation technique preventing the model from overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "fPtGtDL6SKPS",
    "outputId": "1b82b137-db97-4d02-c465-3bdb299ca216"
   },
   "outputs": [],
   "source": [
    "# Create CNN topology\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train_cnn.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#TODO: Change the value of dropout and discuss the differences\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Fit model to data\n",
    "epochs = 3\n",
    "model.fit(x_train_cnn, y_train_cnn, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=(x_val_cnn, y_val_cnn), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6pKAppdSKPX"
   },
   "source": [
    "Evaluate model score on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "l7y_mop4SKPY",
    "outputId": "3e2de660-ca2a-48b6-ba05-ae6a5e03c6a2"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_cnn, y_test_cnn, batch_size=32, verbose=1)\n",
    "print(\"\\nTest accuracy is {}%\".format(100.0*score[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab12.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
